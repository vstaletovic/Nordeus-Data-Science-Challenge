{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "def exploratory_data_analysis(df):\n",
    "    print('Number of Missing values')\n",
    "    print(df.isnull().sum())\n",
    "    print('\\n')\n",
    "\n",
    "    for i in df.columns:\n",
    "        print('COLUMN: {}'.format(i))\n",
    "        if ('id' in i) | ('country' in i):\n",
    "            print('Number of unique values: {}'.format(df[i].nunique()))\n",
    "        else:\n",
    "            if df[i].nunique() < 15:\n",
    "                print(df[i].value_counts())\n",
    "                df[i].value_counts().plot(kind='bar')\n",
    "                plt.title(i)\n",
    "                plt.show()\n",
    "            else:\n",
    "                if df[i].dtype.kind in 'bifc':\n",
    "                    print('Min: {}'.format(df[i].min()))\n",
    "                    print('Max: {}'.format(df[i].max()))\n",
    "                    print('Mean: {}'.format(df[i].mean()))\n",
    "                    print('Median: {}'.format(df[i].median()))\n",
    "                    df[i].plot(kind='kde')\n",
    "                    plt.title(i)\n",
    "                    plt.show()\n",
    "        print('\\n')\n",
    "\n",
    "\n",
    "def preprocess_data(df2):\n",
    "    df2 = df2.drop(['season', 'club_id', 'league_id'], axis=1)\n",
    "    df2['dynamic_payment_segment2'] = df2['dynamic_payment_segment'].str[2:]\n",
    "\n",
    "    dm = pd.get_dummies(df2['dynamic_payment_segment2'])\n",
    "    df2 = pd.concat([df2, dm], axis=1)\n",
    "    df2 = df2.drop(['dynamic_payment_segment', 'dynamic_payment_segment2'], axis=1)\n",
    "    df2 = df2.drop('registration_platform_specific', axis=1)\n",
    "    df2['registration_country_cd'] = pd.Categorical(df2['registration_country'],\n",
    "                                                    categories=df2['registration_country'].unique()).codes\n",
    "    df2 = df2.drop('registration_country', axis=1)\n",
    "    df2['global_competition_level'].fillna(0, inplace=True)\n",
    "\n",
    "    return df2\n",
    "\n",
    "\n",
    "def create_features_and_target(df2):\n",
    "    X = df2.copy().drop('league_rank', axis=1)\n",
    "    Y = df2['league_rank']\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def split(X, Y):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0, stratify=Y)\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "\n",
    "def scale(X_train, X_test):\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "def xgboost_hyper_param(learning_rate, n_estimators, max_depth, gamma):\n",
    "    n_estimators = int(n_estimators)\n",
    "    max_depth = int(max_depth)\n",
    "\n",
    "    clf = XGBRegressor(\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        gamma=gamma,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    return np.mean(cross_val_score(clf, X_train, Y_train, cv=10, scoring='neg_mean_absolute_error'))\n",
    "\n",
    "\n",
    "def optimize_hyperparameters(X_train, Y_train):\n",
    "    pbounds = {\n",
    "        'learning_rate': (0.01, 1.0),\n",
    "        'n_estimators': (100, 1000),\n",
    "        'max_depth': (5, 20),\n",
    "        'gamma': (2, 8)\n",
    "    }\n",
    "\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=xgboost_hyper_param,\n",
    "        pbounds=pbounds,\n",
    "        random_state=1)\n",
    "\n",
    "    optimizer.maximize(init_points=10, n_iter=5)\n",
    "\n",
    "    best_params = optimizer.max['params']\n",
    "\n",
    "    best_params['max_depth'] = int(best_params['max_depth'])\n",
    "    best_params['n_estimators'] = int(best_params['n_estimators'])\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        learning_rate=best_params['learning_rate'],\n",
    "        n_estimators=best_params['n_estimators'],\n",
    "        max_depth=best_params['max_depth'],\n",
    "        gamma=best_params['gamma'],\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return model, best_params\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, Y_test):\n",
    "    err = mae(Y_test, model.predict(X_test))\n",
    "    print('MAE: {}'.format(err))\n",
    "\n",
    "    aa = model.predict(X_test)\n",
    "    aa2 = [14 if i >= 14 else 1 if i <= 1 else round(i) for i in aa]\n",
    "\n",
    "    err2 = mae(Y_test, aa2)\n",
    "    print('MAE Round: {}'.format(err2))\n",
    "\n",
    "\n",
    "def plot_fimportance(model, X):\n",
    "    n_features = X.shape[1]\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.barh(range(n_features), model.feature_importances_)\n",
    "    plt.yticks(np.arange(n_features), X.columns.values)\n",
    "    plt.xlabel('Feature importance')\n",
    "    plt.ylabel('Feature')\n",
    "\n",
    "\n",
    "def make_predictions(df_test, df2, best_params):\n",
    "    df_test2 = preprocess_data(df_test)\n",
    "    X, Y = create_features_and_target(df2)\n",
    "\n",
    "    X_scaled, df5 = scale(X, df_test2)\n",
    "\n",
    "    model2 = XGBRegressor(**best_params, n_jobs=-1, random_state=1)\n",
    "    model2.fit(X_scaled, Y)\n",
    "\n",
    "    plot_fimportance(model2, X)\n",
    "\n",
    "    pp = model2.predict(df5)\n",
    "    pp2 = [14 if i >= 14 else 1 if i <= 1 else round(i) for i in pp]\n",
    "\n",
    "    df_test['league_rank'] = pp2\n",
    "    df_test3 = df_test[['club_id', 'league_rank']].copy()\n",
    "\n",
    "    return df_test3\n",
    "\n",
    "\n",
    "df = pd.read_csv('jobfair_train.csv')\n",
    "exploratory_data_analysis(df)\n",
    "df2 = preprocess_data(df)\n",
    "\n",
    "X, Y = create_features_and_target(df2)\n",
    "X_train, X_test, Y_train, Y_test = split(X, Y)\n",
    "X_train, X_test = scale(X_train, X_test)\n",
    "\n",
    "model, best_params = optimize_hyperparameters(X_train, Y_train)\n",
    "evaluate_model(model, X_test, Y_test)\n",
    "plot_fimportance(model, X)\n",
    "\n",
    "df_test = pd.read_csv('jobfair_test.csv')\n",
    "predictions = make_predictions(df_test, df2, best_params)\n",
    "predictions.to_csv('league_rank_predictions.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
